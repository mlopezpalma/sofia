# ğŸ§  Chat Multi-Modelo con Memoria Vectorial Local

Sistema de chat con IA que implementa memoria semÃ¡ntica vectorial usando embeddings locales gratuitos, ChromaDB para almacenamiento vectorial, y acceso a mÃºltiples LLMs atravÃ©s de OpenRouter.

## ğŸš€ InstalaciÃ³n RÃ¡pida (AutomÃ¡tica)

```bash
# 1. Clonar el repositorio
git clone https://github.com/mlopezpalma/sofia.git
cd sofia

# 2. Ejecutar instalador automÃ¡tico
python setup.py

# El instalador:
# - Crea entorno virtual
# - Instala dependencias
# - Genera archivos de configuraciÃ³n
# - Crea scripts de ejecuciÃ³n
```

## ğŸ› ï¸ InstalaciÃ³n Manual

### 1. Crear entorno virtual

```bash
# Crear entorno
python -m venv venv

# Activar entorno
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. Configurar API Key

```bash
# Copiar archivo de ejemplo
cp .env.example .env

# Editar .env y agregar tu API key real
OPENROUTER_API_KEY=sk-or-tu-api-key-real-aqui
```

### 4. Ejecutar aplicaciÃ³n

```bash
# Windows:
run.bat

# Linux/Mac:
./run.sh

# O manualmente:
python app.py
```

## âš™ï¸ ConfiguraciÃ³n

### Estructura de configuraciÃ³n

```
.env          â†’ Valores secretos (API keys, passwords)
     â†“
config.py     â†’ Lee .env y define configuraciÃ³n
     â†“  
app.py        â†’ Importa todo desde config.py
```

### Variables principales en `.env`

```env
# Requerido
OPENROUTER_API_KEY=tu-api-key-aqui

# Opcional
FLASK_PORT=5000
MAX_TOKENS=2000
TEMPERATURE=0.7
MAX_CONTEXT=5
```

### ConfiguraciÃ³n en `config.py`

- Lista de modelos disponibles
- ConfiguraciÃ³n de embeddings
- LÃ­mites y umbrales
- Rutas de bases de datos

## ğŸ“ Estructura del Proyecto

```
chat-memoria-vectorial/
â”œâ”€â”€ venv/                 # Entorno virtual (no subir a git)
â”œâ”€â”€ app.py               # AplicaciÃ³n principal
â”œâ”€â”€ config.py            # ConfiguraciÃ³n centralizada  
â”œâ”€â”€ setup.py             # Instalador automÃ¡tico
â”œâ”€â”€ .env                 # Variables secretas (no subir a git)
â”œâ”€â”€ .env.example         # Plantilla de variables
â”œâ”€â”€ requirements.txt     # Dependencias
â”œâ”€â”€ run.bat             # Script Windows
â”œâ”€â”€ run.sh              # Script Linux/Mac
â”œâ”€â”€ README.md           # Este archivo
â”‚
â”œâ”€â”€ templates/          # (Auto-generado)
â”‚   â””â”€â”€ index.html     # Interfaz web
â”œâ”€â”€ chroma_db/         # (Auto-generado)
â”‚   â””â”€â”€ [vectores]     # Base vectorial
â””â”€â”€ projects.db        # (Auto-generado)
```

## ğŸ® Uso

### Ejecutar con scripts

```bash
# Windows
run.bat

# Linux/Mac  
./run.sh
```

### Ejecutar manualmente

```bash
# 1. Activar entorno virtual
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# 2. Ejecutar aplicaciÃ³n
python app.py

# 3. Abrir navegador
http://localhost:5000
```

## ğŸ”§ PersonalizaciÃ³n

### Cambiar puerto

En `.env`:
```env
FLASK_PORT=8080
```

### Ajustar lÃ­mites de tokens

En `.env`:
```env
MAX_TOKENS=3000
TEMPERATURE=0.9
```

### Agregar modelos

En `config.py`:
```python
AVAILABLE_MODELS = [
    "openai/gpt-4-turbo-preview",
    "tu-nuevo-modelo/aqui",
    # ...
]
```

## ğŸ› SoluciÃ³n de Problemas

### Error: No module named 'flask'

```bash
# Activar entorno virtual
source venv/bin/activate
pip install -r requirements.txt
```

### Error: API key no configurada

```bash
# Editar .env
OPENROUTER_API_KEY=tu-api-key-real
```

### El modelo tarda en descargar

```bash
# Pre-descargar modelo
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"
```

## ğŸ“Š CaracterÃ­sticas

- âœ… Embeddings locales gratuitos
- âœ… BÃºsqueda semÃ¡ntica inteligente
- âœ… Multi-modelo (GPT-4, Claude, Gemini, etc.)
- âœ… ComparaciÃ³n de respuestas
- âœ… GestiÃ³n de proyectos
- âœ… 100% privacidad local
- âœ… Sin lÃ­mites de uso
- âœ… Costo $0 en infraestructura

## ğŸ’° ComparaciÃ³n de Costos

| SoluciÃ³n | Costo Mensual | Privacidad |
|----------|---------------|------------|
| Este Proyecto | $0 | 100% Local |
| OpenAI + Pinecone | $150-500 | Cloud |
| Azure Cognitive | $200-800 | Cloud |

## ğŸ“ Licencia

MIT License

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crear branch (`git checkout -b feature/nueva`)
3. Commit cambios (`git commit -m 'Add: feature'`)
4. Push (`git push origin feature/nueva`)
5. Crear Pull Request

## ğŸ†˜ Soporte.-- nodisponible 


---

**Recuerda:** Siempre trabaja dentro del entorno virtual (`venv`) para mantener las dependencias aisladas.
